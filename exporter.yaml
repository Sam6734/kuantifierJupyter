---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: pod-runtime-exporter
  namespace: cmsaf-prod
  labels:
    app: pod-runtime-exporter
    component: metrics

---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: pod-runtime-exporter
  namespace: cmsaf-prod
  labels:
    app: pod-runtime-exporter
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: pod-runtime-exporter
  namespace: cmsaf-prod
  labels:
    app: pod-runtime-exporter
subjects:
- kind: ServiceAccount
  name: pod-runtime-exporter
  namespace: cmsaf-prod
roleRef:
  kind: Role
  name: pod-runtime-exporter
  apiGroup: rbac.authorization.k8s.io

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: pod-runtime-exporter-script
  namespace: cmsaf-prod
  labels:
    app: pod-runtime-exporter
data:
  pod_runtime_exporter.py: |
    #!/usr/bin/env python3
    import os, time, sys
    from datetime import datetime, timezone
    from kubernetes import client, config
    from prometheus_client import start_http_server, Gauge

    # prometheus metrics
    pod_endtime   = Gauge('kapel_pod_endtime',   'Pod end time (unix seconds)',   ['namespace','pod','uid'])
    pod_last_seen = Gauge('kapel_pod_last_seen', 'Last time the pod was seen (unix seconds)', ['namespace','pod','uid'])
    pod_cpu_req   = Gauge('kapel_pod_cpu_requests', 'CPU requests (cores)', ['namespace','pod','uid'])

    # config variables 
    WATCH_NAMESPACE   = os.environ.get('WATCH_NAMESPACE', 'cmsaf-prod')
    METRICS_PORT      = int(os.environ.get('METRICS_PORT', '9100'))
    SCAN_INTERVAL     = int(os.environ.get('SCAN_INTERVAL_SECONDS', '30'))
    #number of scans before a pod is considered gone
    MISSING_TOLERANCE = int(os.environ.get('MISSING_TOLERANCE', '1'))

    if __name__ == '__main__':
        start_http_server(METRICS_PORT)
        try:
            config.load_incluster_config()
        except Exception:
            config.load_kube_config()
        v1 = client.CoreV1Api()

        last_seen_map = {} 
        miss_count    = {}  

        print(f"[exporter] Watching namespace {WATCH_NAMESPACE} on port {METRICS_PORT}", file=sys.stderr)

        while True:
            now = datetime.now(timezone.utc).timestamp()
            try:
                pods = v1.list_namespaced_pod(WATCH_NAMESPACE).items
                current = set()

                # gets all the jupyter pods
                for pod in pods:
                    name = pod.metadata.name or ""
                    if not name.startswith('jupyter-'):
                        continue
                    uid = pod.metadata.uid
                    ns = pod.metadata.namespace
                    key = (ns, name, uid)
                    current.add(key)

                    # last seen updates
                    last_seen_map[key] = now
                    pod_last_seen.labels(*key).set(now)

                    # get cpu requests
                    cpu_req = 0.0
                    for c in (pod.spec.containers or []):
                        if c.resources and c.resources.requests:
                            val = c.resources.requests.get('cpu')
                            if not val:
                                continue
                            s = str(val)
                            if s.endswith('m'):
                                cpu_req += float(s[:-1]) / 1000.0
                            else:
                                cpu_req += float(s)
                    if cpu_req > 0:
                        pod_cpu_req.labels(*key).set(cpu_req)

                    # catches terminating pods and marks them with the kapel_pod_endtime metric
                    phase = pod.status.phase or ""
                    if phase in ('Succeeded', 'Failed') or pod.metadata.deletion_timestamp:
                        pod_endtime.labels(*key).set(now)

                # gets pods that stopped before KSM could see them
                previously = set(last_seen_map.keys())
                disappeared = previously - current
                for key in disappeared:
                    miss_count[key] = miss_count.get(key, 0) + 1
                    if miss_count[key] >= MISSING_TOLERANCE:
                        end_ts = last_seen_map.get(key, now)
                        pod_endtime.labels(*key).set(end_ts)
                        last_seen_map.pop(key, None)
                        miss_count.pop(key, None)

                # reset the scan missing count if a pod is still there
                for key in current:
                    miss_count.pop(key, None)

            except Exception as e:
                print(f"[error] {e}", file=sys.stderr)

            time.sleep(SCAN_INTERVAL)



---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pod-runtime-exporter
  namespace: cmsaf-prod
  labels:
    app: pod-runtime-exporter
spec:
  replicas: 1
  selector:
    matchLabels:
      app: pod-runtime-exporter
  template:
    metadata:
      labels:
        app: pod-runtime-exporter
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9100"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: pod-runtime-exporter
      containers:
      - name: exporter
        image: python:3.11-slim
        imagePullPolicy: IfNotPresent
        command:
        - /bin/sh
        - -c
        - |
          set -e
          echo "Installing dependencies..."
          pip install --no-cache-dir kubernetes==28.1.0 prometheus-client==0.19.0
          echo "Starting exporter..."
          python /scripts/pod_runtime_exporter.py
        env:
        - name: WATCH_NAMESPACE
          value: "cmsaf-prod"
        - name: METRICS_PORT
          value: "9100"
        - name: SCAN_INTERVAL_SECONDS
          value: "30"
        - name: MISSING_TOLERANCE
          value: "2"
        volumeMounts:
        - name: script
          mountPath: /scripts
        ports:
        - containerPort: 9100
          name: metrics
          protocol: TCP
        resources:
          limits:
            cpu: 500m
            memory: 256Mi
          requests:
            cpu: 100m
            memory: 128Mi
        livenessProbe:
          httpGet:
            path: /metrics
            port: 9100
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /metrics
            port: 9100
          initialDelaySeconds: 10
          periodSeconds: 10
      volumes:
      - name: script
        configMap:
          name: pod-runtime-exporter-script
          defaultMode: 0755

---
apiVersion: v1
kind: Service
metadata:
  name: pod-runtime-exporter
  namespace: cmsaf-prod
  labels:
    app: pod-runtime-exporter
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9100"
    prometheus.io/path: "/metrics"
spec:
  type: ClusterIP
  selector:
    app: pod-runtime-exporter
  ports:
  - name: metrics
    port: 9100
    targetPort: 9100
    protocol: TCP

---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: pod-runtime-exporter-servicemonitor
  namespace: cmsaf-prod
  labels:
    release: monitoring-kube-prometheus-stack
spec:
  namespaceSelector:
    matchNames:
      - cmsaf-prod
  selector:
    matchLabels:
      app: pod-runtime-exporter
  endpoints:
    - port: metrics
      path: /metrics
      interval: 30s
      honorLabels: true